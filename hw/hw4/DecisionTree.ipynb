{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树-代码实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、构建决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 决策树的数据结构：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./2.png)\n",
    "\n",
    "使用嵌套的字典来记录树\n",
    "\n",
    "![image.png](./4.png)\n",
    "\n",
    "对于上图这样一个决策树，其用字典表示为：\n",
    "\n",
    "```\n",
    "{\n",
    "    \"特征1\":{\n",
    "                \"取值1\":{子树1},\n",
    "                \"取值2\":{子树2}\n",
    "            }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 递归构建决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "createTree(dataset)····················································【dataset的每行是一组数据，每列为一种特征; 返回值是一个字典myTree】\n",
    "    \n",
    "    1、遍历所有特征,找出最优特征 bestFeature\n",
    "       myTree={bestFeature:{}} ········································【使用bestFeature作为根节点，即字典的key】\n",
    "    \n",
    "\n",
    "    2、找出bestFeature的取值列表 bestFeatureValues\n",
    "    \n",
    "    3、for value in bestFeatureValues:\n",
    "\n",
    "          从dataset中，选出 bestFeature=value 的数据，得到newDataset·····【根据bestFeature的取值，划分原数据集为子集newDataSet】\n",
    "        \n",
    "          myTree[bestFeature][value]=createTree(newDataset)·············【递归，从newDataSet构建子树】\n",
    "\n",
    "    4、return myTree\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 递归的停止条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 遍历dataset的标签列：\n",
    "\n",
    "    如果dataset中的所有数据都属于一个标签，说明分类完成，是一个叶子结点\n",
    "    \n",
    "        return 当前dataset所属的标签类别\n",
    "\n",
    "2. 如果所有特征都遍历了，此时仍然有多种特征\n",
    "\n",
    "    也就是说，存在至少两组数据，他们的所有特征都一样，但是他们所属的标签类别不一样\n",
    "\n",
    "        return 当前dataset中更多的标签类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 找最优特征（手册6.1.3【chooseBestFeatureToSplit(dataSet)】）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历所有特征，计算信息增益\n",
    "\n",
    "1. 计算数据集的信息熵····································计算信息熵：手册6.1.2节【calcShannonEnt(dataSet)】函数\n",
    "2. 对于每一个特征：\n",
    "    1. 根据特征的不同取值划分子集························构建子集：手册上6.1.3节【splitDataSet(dataSet, axis, value)】函数\n",
    "    2. 计算子集的平均信息熵\n",
    "    3. 计算信息增益=子集的平均信息熵-原数据集的信息熵\n",
    "    4. 信息增益最大的为最优特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二、根据决策树对数据分类（手册6.1.5【classify(inputTree,labels, testVec)】）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "递归地访问决策树字典直到访问到叶子结点，\n",
    "\n",
    "判断叶子结点：叶子结点是标签类别而不是字典\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no surfacing', 'flippers']\n",
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "# 函数说明:创建测试数据集\n",
    "def createDataSet():\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    无\n",
    "    Returns:\n",
    "    dataSet - 数据集\n",
    "    labels - 分类属性\n",
    "    \"\"\"\n",
    "    dataSet = [[1, 1, 'yes'],#数据集\n",
    "            [1, 1, 'yes'],\n",
    "            [1, 0, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']#分类属性\n",
    "    return dataSet, labels#返回数据集和分类属性\n",
    "\n",
    "dataSet, labels = createDataSet()\n",
    "print(labels)\n",
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、构建决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 选择最优特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前数据集的最优特征的下标为（即决策树的根节点为）：0\n",
      "即：no surfacing\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "# 函数说明:计算给定数据集的经验熵(香农熵)\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    dataSet - 数据集\n",
    "    Returns:\n",
    "    shannonEnt - 经验熵(香农熵)\n",
    "    \"\"\"\n",
    "    numEntires = len(dataSet) #返回数据集的行数\n",
    "    labelCounts = {} #保存每个标签(Label)出现次数的字典\n",
    "    for featVec in dataSet: #对每组特征向量进行统计\n",
    "        currentLabel = featVec[-1] #提取标签(Label)信息\n",
    "        if currentLabel not in labelCounts.keys(): #如果标签(Label)没有放入统计次数的字典,添加进去\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1 #Label计数\n",
    "    shannonEnt = 0.0 #经验熵(香农熵)\n",
    "    for key in labelCounts: #计算香农熵\n",
    "        prob = float(labelCounts[key]) / numEntires #选择该标签(Label)的概率\n",
    "        shannonEnt -= prob * log(prob, 2) #利用公式计算\n",
    "    return shannonEnt #返回经验熵(香农熵)\n",
    "\n",
    "\n",
    "# 函数说明:按照给定特征划分数据集\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    dataSet - 待划分的数据集\n",
    "    axis - 划分数据集的特征\n",
    "    value - 需要返回的特征的值\n",
    "    Returns:\n",
    "    无\n",
    "    64\n",
    "    6.1 决策树\n",
    "    \"\"\"\n",
    "    retDataSet = [] #创建返回的数据集列表\n",
    "    for featVec in dataSet: #遍历数据集\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis] #去掉axis特征\n",
    "            reducedFeatVec.extend(featVec[axis+1:])#将符合条件的添加到返回的数据集\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    dataSet - 数据集\n",
    "    Returns:\n",
    "    bestFeature - 信息增益最大的(最优)特征的索引值\n",
    "    \"\"\"\n",
    "    # 函数说明:选择最优特征\n",
    "    numFeatures = len(dataSet[0]) - 1 #特征数量\n",
    "    baseEntropy = calcShannonEnt(dataSet) #计算数据集的香农熵\n",
    "    bestInfoGain = 0.0 #信息增益\n",
    "    bestFeature = -1 #最优特征的索引值\n",
    "    for i in range(numFeatures): #遍历所有特征\n",
    "        #获取dataSet的第i个所有特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList) #创建set集合{},元素不可重复\n",
    "        newEntropy = 0.0 #经验条件熵\n",
    "        for value in uniqueVals: #计算信息增益\n",
    "            subDataSet = splitDataSet(dataSet, i, value) #subDataSet划分后的子集\n",
    "            prob = len(subDataSet) / float(len(dataSet)) #计算子集的概率\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)#根据公式计算经验条件熵\n",
    "        infoGain = baseEntropy - newEntropy #信息增益\n",
    "        #print(\"第%d个特征的增益为%.3f\" % (i, infoGain)) #打印每个特征的信息增益\n",
    "        if (infoGain > bestInfoGain): #计算信息增益\n",
    "            bestInfoGain = infoGain #更新信息增益，找到最大的信息增益\n",
    "            bestFeature = i #记录信息增益最大的特征的索引值\n",
    "    return bestFeature #返回信息增益最大的特征的索引值\n",
    "\n",
    "\n",
    "print(f\"当前数据集的最优特征的下标为（即决策树的根节点为）：{chooseBestFeatureToSplit(dataSet)}\")\n",
    "print(f\"即：{labels[chooseBestFeatureToSplit(dataSet)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "构建决策树如下:\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "# 函数说明:统计classList中出现此处最多的元素(类标签)\n",
    "def majorityCnt(classList):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    classList - 类标签列表\n",
    "    Returns:\n",
    "    sortedClassCount[0][0] - 出现此处最多的元素(类标签)\n",
    "    \"\"\"\n",
    "    classCount = {}\n",
    "    for vote in classList:#统计classList中每个元素出现的次数\n",
    "        if vote not in classCount.keys():classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)#根据字典的值降序排序\n",
    "    return sortedClassCount[0][0]#返回classList中出现次数最多的元素\n",
    "\n",
    "\n",
    "# 函数说明:创建决策树\n",
    "def createTree(dataSet, labels):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    dataSet - 训练数据集\n",
    "    labels - 分类属性标签\n",
    "    Returns:\n",
    "    myTree - 决策树\n",
    "    \"\"\"\n",
    "    classList = [example[-1] for example in dataSet] #取分类标签(是否放贷:yes or no)\n",
    "    if classList.count(classList[0]) == len(classList): #如果类别完全相同则停止继续划分\n",
    "        return classList[0]\n",
    "    \n",
    "    if len(dataSet[0]) == 1: #遍历完所有特征时返回出现次数最多的类标签\n",
    "        return majorityCnt(classList)\n",
    "    \n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) #选择最优特征\n",
    "    bestFeatLabel = labels[bestFeat] #最优特征的标签\n",
    "    myTree = {bestFeatLabel:{}} #根据最优特征的标签生成树\n",
    "\n",
    "    del(labels[bestFeat]) #删除已经使用特征标签\n",
    "    #（因为dataSet的bestFeat特征在划分子集时被删掉，所以labels也要删掉对应的特征名称）\n",
    "\n",
    "    featValues = [example[bestFeat] for example in dataSet]#得到训练集中所有最优特征的属性值\n",
    "    uniqueVals = set(featValues) #去掉重复的属性值\n",
    "\n",
    "    for value in uniqueVals: #遍历特征，创建决策树。\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), labels)\n",
    "    return myTree\n",
    "\n",
    "temp = labels[:]\n",
    "myTree = createTree(dataSet, temp)\n",
    "print(f\"\\n构建决策树如下:\\n{myTree}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用决策树分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "对数据[1, 1]的分类结果为：\n",
      "yes\n",
      "\n",
      "对数据[1, 0]的分类结果为：\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "# 函数说明:使用决策树分类\n",
    "def classify(inputTree,labels, testVec):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    inputTree - 已经生成的决策树\n",
    "    testVec - 测试数据\n",
    "    Returns:\n",
    "    classLabel - 分类结果\n",
    "    \"\"\"\n",
    "    firstStr = next(iter(inputTree)) #获取决策树结点\n",
    "    #print(f\"firstStr={firstStr}\")\n",
    "    secondDict = inputTree[firstStr] #下一个字典\n",
    "    #print(f\"secondDict={secondDict}\")\n",
    "    featIndex = labels.index(firstStr)\n",
    "    #print(f\"featIndex={featIndex}\")\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], labels, testVec)\n",
    "            else: classLabel = secondDict[key]\n",
    "    return classLabel\n",
    "\n",
    "testVec = [1,1]#测试数据\n",
    "result = classify(myTree,labels,testVec)\n",
    "print(f\"\\n对数据{testVec}的分类结果为：\\n{result}\")\n",
    "\n",
    "testVec = [1,0]#测试数据\n",
    "result = classify(myTree,labels,testVec)\n",
    "print(f\"\\n对数据{testVec}的分类结果为：\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn实现决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classfier = DecisionTreeClassifier()\n",
    "\n",
    "classfier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](6.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
