{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张峪齐 3200105176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "房价预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (1460, 81)\n",
      "test_data.shape: (1459, 80)\n",
      "all_features: (2919, 79)\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg\n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg\n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1\n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1\n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#读取csv数据\n",
    "train_data = pandas.read_csv(\"kaggle_house_pred_train.csv\")\n",
    "test_data = pandas.read_csv(\"kaggle_house_pred_test.csv\")\n",
    "#把去掉id的数据拼在一起，去掉id的目的是为了防止模型通过记住编号得到对应房价。\n",
    "all_features = pandas.concat(( train_data.iloc[:,1:-1], test_data.iloc[:,1:]))\n",
    "print(\"train_data.shape:\",train_data.shape)\n",
    "print(\"test_data.shape:\",test_data.shape)\n",
    "print(\"all_features:\",all_features.shape)\n",
    "print(train_data.iloc[:5,:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 处理缺省值和属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_features.shape: (2919, 331)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleType_nan</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleCondition_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067320</td>\n",
       "      <td>-0.184443</td>\n",
       "      <td>-0.217841</td>\n",
       "      <td>0.646073</td>\n",
       "      <td>-0.507197</td>\n",
       "      <td>1.046078</td>\n",
       "      <td>0.896679</td>\n",
       "      <td>0.523038</td>\n",
       "      <td>0.580708</td>\n",
       "      <td>-0.29303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.873466</td>\n",
       "      <td>0.458096</td>\n",
       "      <td>-0.072032</td>\n",
       "      <td>-0.063174</td>\n",
       "      <td>2.187904</td>\n",
       "      <td>0.154737</td>\n",
       "      <td>-0.395536</td>\n",
       "      <td>-0.569893</td>\n",
       "      <td>1.177709</td>\n",
       "      <td>-0.29303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067320</td>\n",
       "      <td>-0.055935</td>\n",
       "      <td>0.137173</td>\n",
       "      <td>0.646073</td>\n",
       "      <td>-0.507197</td>\n",
       "      <td>0.980053</td>\n",
       "      <td>0.848819</td>\n",
       "      <td>0.333448</td>\n",
       "      <td>0.097840</td>\n",
       "      <td>-0.29303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302516</td>\n",
       "      <td>-0.398622</td>\n",
       "      <td>-0.078371</td>\n",
       "      <td>0.646073</td>\n",
       "      <td>-0.507197</td>\n",
       "      <td>-1.859033</td>\n",
       "      <td>-0.682695</td>\n",
       "      <td>-0.569893</td>\n",
       "      <td>-0.494771</td>\n",
       "      <td>-0.29303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067320</td>\n",
       "      <td>0.629439</td>\n",
       "      <td>0.518814</td>\n",
       "      <td>1.355319</td>\n",
       "      <td>-0.507197</td>\n",
       "      <td>0.947040</td>\n",
       "      <td>0.753100</td>\n",
       "      <td>1.381770</td>\n",
       "      <td>0.468770</td>\n",
       "      <td>-0.29303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    0.067320    -0.184443 -0.217841     0.646073    -0.507197   1.046078   \n",
       "1   -0.873466     0.458096 -0.072032    -0.063174     2.187904   0.154737   \n",
       "2    0.067320    -0.055935  0.137173     0.646073    -0.507197   0.980053   \n",
       "3    0.302516    -0.398622 -0.078371     0.646073    -0.507197  -1.859033   \n",
       "4    0.067320     0.629439  0.518814     1.355319    -0.507197   0.947040   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_Oth  \\\n",
       "0      0.896679    0.523038    0.580708    -0.29303  ...             0   \n",
       "1     -0.395536   -0.569893    1.177709    -0.29303  ...             0   \n",
       "2      0.848819    0.333448    0.097840    -0.29303  ...             0   \n",
       "3     -0.682695   -0.569893   -0.494771    -0.29303  ...             0   \n",
       "4      0.753100    1.381770    0.468770    -0.29303  ...             0   \n",
       "\n",
       "   SaleType_WD  SaleType_nan  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0            1             0                      0                      0   \n",
       "1            1             0                      0                      0   \n",
       "2            1             0                      0                      0   \n",
       "3            1             0                      1                      0   \n",
       "4            1             0                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  SaleCondition_nan  \n",
       "0                      0                  0  \n",
       "1                      0                  0  \n",
       "2                      0                  0  \n",
       "3                      0                  0  \n",
       "4                      0                  0  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提取全是数字的特征名字\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "#对数据做标准化处理,对应位置赋值\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.\n",
    "std()))\n",
    "# 在标准化数据之后，将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "#‘Dummy_na=True‘ 将“na”（缺失值）视为有效的特征值，并为其创建指示符特征。\n",
    "# pandas.get_dummies把特征为类别值或离散值分成每一个特征为一个类别。\n",
    "all_features = pandas.get_dummies(all_features, dummy_na = True)\n",
    "print(\"all_features.shape:\",all_features.shape)\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分成训练数据和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: torch.Size([1460, 331])\n",
      "train_features.shape: torch.Size([1459, 331])\n",
      "train_labels: torch.Size([1460, 1])\n"
     ]
    }
   ],
   "source": [
    "#把数据分成训练数据和测试数据\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype = torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype = torch.float32)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1, 1), dtype = torch.float32)\n",
    "print(\"train_features.shape:\", train_features.shape)\n",
    "print(\"train_features.shape:\", test_features.shape)\n",
    "print(\"train_labels:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一批32个，一共46批\n",
      "1 49109938176.0\n",
      "2 39665479680.0\n",
      "3 39433764864.0\n",
      "4 32866015232.0\n",
      "5 32497242112.0\n",
      "6 30558787584.0\n",
      "7 33248145408.0\n",
      "8 65288208384.0\n",
      "9 52882448384.0\n",
      "10 55420018688.0\n",
      "11 28603338752.0\n",
      "12 61241622528.0\n",
      "13 44495171584.0\n",
      "14 24299137024.0\n",
      "15 26018551808.0\n",
      "16 30928211968.0\n",
      "17 31835133952.0\n",
      "18 27065925632.0\n",
      "19 23941328896.0\n",
      "20 66265751552.0\n",
      "21 25587990528.0\n",
      "22 27278602240.0\n",
      "23 30830696448.0\n",
      "24 17208514560.0\n",
      "25 23676514304.0\n",
      "26 31165829120.0\n",
      "27 28598278144.0\n",
      "28 26951204864.0\n",
      "29 33704863744.0\n",
      "30 28713091072.0\n",
      "31 20765417472.0\n",
      "32 28120170496.0\n",
      "33 26314598400.0\n",
      "34 17858347008.0\n",
      "35 21402687488.0\n",
      "36 33349851136.0\n",
      "37 34439749632.0\n",
      "38 15785047040.0\n",
      "39 15558713344.0\n",
      "40 12671208448.0\n",
      "41 17855744000.0\n",
      "42 10773718016.0\n",
      "43 18462636032.0\n",
      "44 13656916992.0\n",
      "45 17154012160.0\n",
      "46 14082526208.0\n",
      "47 12219982848.0\n",
      "48 11577463808.0\n",
      "49 13102811136.0\n",
      "50 10144778240.0\n",
      "51 7128185856.0\n",
      "52 9163458560.0\n",
      "53 10614412288.0\n",
      "54 3357287424.0\n",
      "55 6584056320.0\n",
      "56 2817230080.0\n",
      "57 1467966080.0\n",
      "58 4056416768.0\n",
      "59 7371965952.0\n",
      "60 1051940160.0\n",
      "61 2717610752.0\n",
      "62 3938490368.0\n",
      "63 2808376832.0\n",
      "64 3885903104.0\n",
      "65 5851416576.0\n",
      "66 748850368.0\n",
      "67 2621370624.0\n",
      "68 480571744.0\n",
      "69 1366898944.0\n",
      "70 7903144448.0\n",
      "71 957326720.0\n",
      "72 893671616.0\n",
      "73 1514187520.0\n",
      "74 1926760192.0\n",
      "75 1463870720.0\n",
      "76 1460965504.0\n",
      "77 987914240.0\n",
      "78 1486017792.0\n",
      "79 4270706688.0\n",
      "80 6951031808.0\n",
      "81 2853495552.0\n",
      "82 1088755200.0\n",
      "83 843983104.0\n",
      "84 771085440.0\n",
      "85 726354368.0\n",
      "86 409607936.0\n",
      "87 439421888.0\n",
      "88 406280192.0\n",
      "89 1237151488.0\n",
      "90 1495035520.0\n",
      "91 1884866560.0\n",
      "92 656634240.0\n",
      "93 5223356416.0\n",
      "94 2097269760.0\n",
      "95 2124593536.0\n",
      "96 842449792.0\n",
      "97 642210432.0\n",
      "98 523645376.0\n",
      "99 839618816.0\n",
      "100 352140672.0\n",
      "101 1498048896.0\n",
      "102 517170112.0\n",
      "103 1808375808.0\n",
      "104 508201728.0\n",
      "105 1304505600.0\n",
      "106 732014272.0\n",
      "107 614077312.0\n",
      "108 423974816.0\n",
      "109 1368316544.0\n",
      "110 1442566144.0\n",
      "111 12656256000.0\n",
      "112 1453391360.0\n",
      "113 1609145600.0\n",
      "114 1252457728.0\n",
      "115 1232696064.0\n",
      "116 587523008.0\n",
      "117 685357760.0\n",
      "118 897175360.0\n",
      "119 423277760.0\n",
      "120 517320896.0\n",
      "121 677136960.0\n",
      "122 1336935040.0\n",
      "123 1213104256.0\n",
      "124 784009216.0\n",
      "125 591378112.0\n",
      "126 358578176.0\n",
      "127 1167193856.0\n",
      "128 5162510336.0\n",
      "129 4111854336.0\n",
      "130 258300160.0\n",
      "131 593927296.0\n",
      "132 230227040.0\n",
      "133 727831680.0\n",
      "134 218670496.0\n",
      "135 869946176.0\n",
      "136 1248950016.0\n",
      "137 982831616.0\n",
      "138 422767808.0\n",
      "139 542531904.0\n",
      "140 1089025152.0\n",
      "141 982316928.0\n",
      "142 295775040.0\n",
      "143 765414720.0\n",
      "144 850211904.0\n",
      "145 1149942656.0\n",
      "146 775542656.0\n",
      "147 358652512.0\n",
      "148 1261361664.0\n",
      "149 479881568.0\n",
      "150 379159040.0\n",
      "151 11377120256.0\n",
      "152 650550336.0\n",
      "153 444091584.0\n",
      "154 5947903488.0\n",
      "155 2630166016.0\n",
      "156 519214144.0\n",
      "157 326527008.0\n",
      "158 1062288576.0\n",
      "159 658012800.0\n",
      "160 11124020224.0\n",
      "161 429834944.0\n",
      "162 1522941696.0\n",
      "163 1874429312.0\n",
      "164 1011949248.0\n",
      "165 1022231744.0\n",
      "166 2520610304.0\n",
      "167 696470592.0\n",
      "168 442595648.0\n",
      "169 310463648.0\n",
      "170 830882304.0\n",
      "171 832361792.0\n",
      "172 2122851968.0\n",
      "173 394472320.0\n",
      "174 1308684672.0\n",
      "175 443771552.0\n",
      "176 486830912.0\n",
      "177 700129408.0\n",
      "178 214363040.0\n",
      "179 542600320.0\n",
      "180 2551379200.0\n",
      "181 929505664.0\n",
      "182 1752581888.0\n",
      "183 334059456.0\n",
      "184 733909696.0\n",
      "185 612974208.0\n",
      "186 828813440.0\n",
      "187 431317344.0\n",
      "188 1546661504.0\n",
      "189 590377728.0\n",
      "190 411399712.0\n",
      "191 5200254464.0\n",
      "192 736739712.0\n",
      "193 561748352.0\n",
      "194 2505776896.0\n",
      "195 1017269568.0\n",
      "196 199553888.0\n",
      "197 683079552.0\n",
      "198 792489856.0\n",
      "199 334955264.0\n",
      "200 236207872.0\n",
      "201 219107616.0\n",
      "202 380324608.0\n",
      "203 609462400.0\n",
      "204 953349952.0\n",
      "205 316279872.0\n",
      "206 3239040000.0\n",
      "207 13033234432.0\n",
      "208 368845728.0\n",
      "209 302542240.0\n",
      "210 297315392.0\n",
      "211 806530368.0\n",
      "212 516803936.0\n",
      "213 313395744.0\n",
      "214 9634243584.0\n",
      "215 1057052544.0\n",
      "216 723900544.0\n",
      "217 561608512.0\n",
      "218 385760352.0\n",
      "219 5790291456.0\n",
      "220 2824473600.0\n",
      "221 227618992.0\n",
      "222 2458884096.0\n",
      "223 250797136.0\n",
      "224 381717600.0\n",
      "225 545937536.0\n",
      "226 1473704448.0\n",
      "227 925785728.0\n",
      "228 240431104.0\n",
      "229 513225312.0\n",
      "230 591135552.0\n",
      "231 340200672.0\n",
      "232 802087296.0\n",
      "233 220849616.0\n",
      "234 1078802176.0\n",
      "235 463864320.0\n",
      "236 1439521536.0\n",
      "237 716213952.0\n",
      "238 950872960.0\n",
      "239 731409600.0\n",
      "240 358917184.0\n",
      "241 890596224.0\n",
      "242 456222368.0\n",
      "243 577651712.0\n",
      "244 627719808.0\n",
      "245 5732116480.0\n",
      "246 649683840.0\n",
      "247 5733153792.0\n",
      "248 130616960.0\n",
      "249 260135040.0\n",
      "250 700657344.0\n",
      "251 250407760.0\n",
      "252 401154400.0\n",
      "253 366506080.0\n",
      "254 227545904.0\n",
      "255 436122048.0\n",
      "256 13090078720.0\n",
      "257 1622115328.0\n",
      "258 473306560.0\n",
      "259 388916480.0\n",
      "260 1040897024.0\n",
      "261 328082720.0\n",
      "262 831980480.0\n",
      "263 145720160.0\n",
      "264 1217363584.0\n",
      "265 410901184.0\n",
      "266 832476736.0\n",
      "267 594163776.0\n",
      "268 436266400.0\n",
      "269 2214469120.0\n",
      "270 788936320.0\n",
      "271 215067552.0\n",
      "272 1137624320.0\n",
      "273 382035296.0\n",
      "274 1001410688.0\n",
      "275 309627776.0\n",
      "276 272168352.0\n",
      "277 105159248.0\n",
      "278 199547440.0\n",
      "279 730250176.0\n",
      "280 370192096.0\n",
      "281 996724096.0\n",
      "282 627921472.0\n",
      "283 583639552.0\n",
      "284 514069568.0\n",
      "285 660944320.0\n",
      "286 12775788544.0\n",
      "287 1151846656.0\n",
      "288 689397632.0\n",
      "289 360748320.0\n",
      "290 299093536.0\n",
      "291 1453828352.0\n",
      "292 562817024.0\n",
      "293 4319763456.0\n",
      "294 367845088.0\n",
      "295 579819904.0\n",
      "296 450459328.0\n",
      "297 401306272.0\n",
      "298 314936448.0\n",
      "299 1165002112.0\n",
      "300 243403232.0\n",
      "301 434199232.0\n",
      "302 375535968.0\n",
      "303 289211520.0\n",
      "304 323401376.0\n",
      "305 1546614656.0\n",
      "306 599447488.0\n",
      "307 235361616.0\n",
      "308 429418592.0\n",
      "309 370388928.0\n",
      "310 339886400.0\n",
      "311 290337216.0\n",
      "312 168268336.0\n",
      "313 577693696.0\n",
      "314 333550496.0\n",
      "315 375136672.0\n",
      "316 6040699392.0\n",
      "317 560185088.0\n",
      "318 799691008.0\n",
      "319 329771680.0\n",
      "320 1803501312.0\n",
      "321 822128000.0\n",
      "322 2022488448.0\n",
      "323 1181213952.0\n",
      "324 533158592.0\n",
      "325 813861760.0\n",
      "326 632436032.0\n",
      "327 537812608.0\n",
      "328 1646144896.0\n",
      "329 1042763136.0\n",
      "330 1623607168.0\n",
      "331 367830336.0\n",
      "332 499275712.0\n",
      "333 412910432.0\n",
      "334 708881792.0\n",
      "335 2250660864.0\n",
      "336 308290080.0\n",
      "337 296609856.0\n",
      "338 230730928.0\n",
      "339 329273728.0\n",
      "340 379776864.0\n",
      "341 631824896.0\n",
      "342 465380096.0\n",
      "343 478537888.0\n",
      "344 292738912.0\n",
      "345 397832192.0\n",
      "346 1169125632.0\n",
      "347 166681888.0\n",
      "348 3878064640.0\n",
      "349 432027648.0\n",
      "350 171608320.0\n",
      "351 273286624.0\n",
      "352 164800800.0\n",
      "353 447116032.0\n",
      "354 388235584.0\n",
      "355 487014976.0\n",
      "356 1087039360.0\n",
      "357 629809600.0\n",
      "358 13582642176.0\n",
      "359 348351712.0\n",
      "360 167681328.0\n",
      "361 348017632.0\n",
      "362 363217888.0\n",
      "363 1776932096.0\n",
      "364 724768640.0\n",
      "365 816348416.0\n",
      "366 367227104.0\n",
      "367 761717888.0\n",
      "368 1216988800.0\n",
      "369 2172443392.0\n",
      "370 267138848.0\n",
      "371 364648736.0\n",
      "372 430600096.0\n",
      "373 194668976.0\n",
      "374 502348800.0\n",
      "375 301901088.0\n",
      "376 280406688.0\n",
      "377 741593984.0\n",
      "378 518010464.0\n",
      "379 289068992.0\n",
      "380 316513024.0\n",
      "381 470167808.0\n",
      "382 354643296.0\n",
      "383 1854113792.0\n",
      "384 178738272.0\n",
      "385 460675904.0\n",
      "386 384384928.0\n",
      "387 1350803712.0\n",
      "388 430652864.0\n",
      "389 299216480.0\n",
      "390 1821812352.0\n",
      "391 447787680.0\n",
      "392 130201704.0\n",
      "393 355517248.0\n",
      "394 182325808.0\n",
      "395 222397056.0\n",
      "396 210706832.0\n",
      "397 3784723712.0\n",
      "398 498572352.0\n",
      "399 719522112.0\n",
      "400 331209888.0\n",
      "401 287259360.0\n",
      "402 319191264.0\n",
      "403 439427776.0\n",
      "404 6256454144.0\n",
      "405 261054304.0\n",
      "406 283152960.0\n",
      "407 173757776.0\n",
      "408 330507232.0\n",
      "409 176350960.0\n",
      "410 154974368.0\n",
      "411 327313504.0\n",
      "412 249258880.0\n",
      "413 354964384.0\n",
      "414 1516060800.0\n",
      "415 1654917376.0\n",
      "416 681686464.0\n",
      "417 568918528.0\n",
      "418 318968960.0\n",
      "419 200864208.0\n",
      "420 827692544.0\n",
      "421 1102539136.0\n",
      "422 593976128.0\n",
      "423 1872819968.0\n",
      "424 562654016.0\n",
      "425 441536320.0\n",
      "426 403000256.0\n",
      "427 449863776.0\n",
      "428 482546272.0\n",
      "429 763401920.0\n",
      "430 197782048.0\n",
      "431 3507446528.0\n",
      "432 299588928.0\n",
      "433 1485542016.0\n",
      "434 366844224.0\n",
      "435 464232768.0\n",
      "436 334629056.0\n",
      "437 219667680.0\n",
      "438 204890208.0\n",
      "439 187312336.0\n",
      "440 533509056.0\n",
      "441 336735616.0\n",
      "442 1855723904.0\n",
      "443 653729152.0\n",
      "444 757834432.0\n",
      "445 282685312.0\n",
      "446 270512576.0\n",
      "447 225258544.0\n",
      "448 146325456.0\n",
      "449 1019842048.0\n",
      "450 416862656.0\n",
      "451 716469440.0\n",
      "452 287856704.0\n",
      "453 237773536.0\n",
      "454 397754208.0\n",
      "455 208848016.0\n",
      "456 320830304.0\n",
      "457 1307727872.0\n",
      "458 211615552.0\n",
      "459 467145888.0\n",
      "460 531518976.0\n",
      "461 131367144.0\n",
      "462 833101696.0\n",
      "463 586760640.0\n",
      "464 231406720.0\n",
      "465 1827341568.0\n",
      "466 229550672.0\n",
      "467 666238976.0\n",
      "468 652246144.0\n",
      "469 1744591488.0\n",
      "470 408164768.0\n",
      "471 768970240.0\n",
      "472 176931024.0\n",
      "473 323985504.0\n",
      "474 409059520.0\n",
      "475 338181600.0\n",
      "476 266464512.0\n",
      "477 364032928.0\n",
      "478 474974880.0\n",
      "479 301256032.0\n",
      "480 191510288.0\n",
      "481 385176256.0\n",
      "482 263736240.0\n",
      "483 331072416.0\n",
      "484 455862208.0\n",
      "485 237348768.0\n",
      "486 246451872.0\n",
      "487 398978656.0\n",
      "488 1854464256.0\n",
      "489 432622336.0\n",
      "490 318359648.0\n",
      "491 224019104.0\n",
      "492 294603680.0\n",
      "493 203814432.0\n",
      "494 1720783872.0\n",
      "495 542548864.0\n",
      "496 305321824.0\n",
      "497 340958496.0\n",
      "498 203357792.0\n",
      "499 155148192.0\n",
      "500 342445376.0\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "  \n",
    "    def __init__(self, features):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear_relu1 = nn.Linear(features, 512)\n",
    "        self.linear_relu3 = nn.Linear(512, 256)\n",
    "        self.linear5 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.linear_relu1(x)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear_relu3(y_pred)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear5(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "model = Net(features=train_features.shape[1])\n",
    "\n",
    "# 使用均方误差作为损失函数\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "losses = []\n",
    "#animator = d2l.Animator(xlabel='epoch', xlim=[1, 500], ylim=[0.0, 1.0],legend=['train loss'])\n",
    "\n",
    "batch_size = 32\n",
    "dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, # 数据\n",
    "    batch_size = batch_size, # 每个batch大小\n",
    "    shuffle = True, # 是否打乱数据\n",
    "    num_workers = 0, # 工作线程\n",
    "    pin_memory = True)\n",
    "\n",
    "print(f\"每一批{len(next(iter(train_loader))[0])}个，一共{len(train_loader)}批\")\n",
    "\n",
    "# 训练500epoch\n",
    "epoch_count=0;\n",
    "for i in range(0,500):\n",
    "    epoch_count+=1;\n",
    "    for X, y in train_loader:     \n",
    "        #for t in range(5000):\n",
    "        train_features\n",
    "        #y_pred = model(train_features)\n",
    "        y_pred = model(X)\n",
    "\n",
    "        #loss = criterion(y_pred, train_labels)\n",
    "        loss=criterion(y_pred,y)\n",
    "        #print(t, loss.item())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        #animator.add(t, loss.item())\n",
    "        if torch.isnan(loss):\n",
    "            break\n",
    "        \n",
    "        # 将模型中各参数的梯度清零。\n",
    "        # PyTorch的backward()方法计算梯度会默认将本次计算的梯度与缓存中已有的梯度加和。\n",
    "        # 必须在反向传播前先清零。\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 反向传播，计算各参数对于损失loss的梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        # 根据刚刚反向传播得到的梯度更新模型参数\n",
    "        optimizer.step()\n",
    "    print(epoch_count,loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据分批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一批32个，一共46批\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, # 数据\n",
    "    batch_size = batch_size, # 每个batch大小\n",
    "    shuffle = True, # 是否打乱数据\n",
    "    num_workers = 0, # 工作线程\n",
    "    pin_memory = True)\n",
    "\n",
    "print(f\"每一批{len(next(iter(train_loader))[0])}个，一共{len(train_loader)}批\")\n",
    "\n",
    "#for X, y in train_loader:\n",
    "#    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class MyNet(nn.Module):\n",
    "#    def __init__(self, in_put, hidden, hidden1, out_put):\n",
    "#        super().__init__()\n",
    "#        self.in_put=in_put #接收331维的输入，输出1024维度\n",
    "#        self.hidden=hidden\n",
    "#        self.hidden1=hidden1 # 接收256维度，输出1维(房价)\n",
    "#        self.out_put=out_put\n",
    "        # Codes\n",
    "\n",
    "#    def forward(self, data):\n",
    "        # Codes\n",
    "#        return self.out_put(self.hidden1(self.hidden(self.in_put(data))))\n",
    "net = nn.Sequential(nn.Linear(331,256),nn.ReLU(),nn.Linear(256,1))\n",
    "#net=MyNet(nn.Linear(331,1024),nn.ReLU(),nn.Linear(1024,1024),nn.Linear(1024,1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 初始化神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化参数\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_weights);\n",
    "\n",
    "#将模型放到GPU上\n",
    "def try_gpu(i=0):  #尝试获取gpu设备\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "#net = net.to(device=try_gpu())\n",
    "\n",
    "#损失函数loss(xi,yi)=(xiyi)2\n",
    "loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "#梯度优化算法\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义loss图像绘图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练神经网络并绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator: #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y): #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater): #@save\n",
    "    \"\"\"训练模型一个迭代周期\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    #if isinstance(net, torch.nn.Module):\n",
    "    net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        #将batch移到gpu上\n",
    "        #X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def train(net, train_iter, loss, num_epochs, updater): #@save\n",
    "\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.0, 1.0],\n",
    "    legend=['train loss', 'train acc'])\n",
    "    #epoch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        train_loss,train_acc = train_metrics\n",
    "        print(f\"train_loss= {train_loss} , train_acc={train_acc}\")\n",
    "        #animator.add(epoch + 1, train_metrics )\n",
    "        #print(f\"{epoch_count} epoches trained\")\n",
    "        #epoch_count+=1\n",
    "    train_loss,train_acc = train_metrics\n",
    "    #assert train_loss < 0.5, train_loss\n",
    "    #assert train_acc <= 1 and train_acc > 0.7, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n",
      "train_loss= nan , train_acc=0.0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-07-13T16:27:46.204579</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 173.477344 \n",
       "L 240.554688 173.477344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m7c2a8b3968\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7c2a8b3968\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m5bc395cfa9\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 153.398438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 125.678438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 97.958438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 70.238438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 42.518438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5bc395cfa9\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs=150\n",
    "train(net,train_loader,loss,num_epochs,trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 测试神经网络生成提交数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(model,test_features):\n",
    "    test_features = test_features.to(device=try_gpu())\n",
    "    preds = model(test_features).detach().to(\"cpu\").numpy()\n",
    "    print(preds.squeeze().shape)\n",
    "\n",
    "    #pandas.Series 创建新维度\n",
    "    test_data['SalePrice'] = pandas.Series(preds.squeeze())\n",
    "              \n",
    "    #axis选择拼接的维度\n",
    "    return pandas.concat([test_data['Id'], test_data['SalePrice']], axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
